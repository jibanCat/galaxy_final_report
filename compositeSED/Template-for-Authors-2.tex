% template.tex, dated April 5 2013
% This is a template file for Annual Reviews 1 column Journals
%
% Compilation using ar-1col.cls' - version 1.0, Aptara Inc.
% (c) 2013 AR
%
% Steps to compile: latex latex latex
%
% For tracking purposes => this is v1.0 - Apr. 2013
% 
% Suggestion: 
% Do the figures first, and then write the stories.

\documentclass{ar-1col}
\usepackage{natbib}
\usepackage{algorithm2e}

\setcounter{secnumdepth}{4}
\usepackage{url}

% Metadata Information
\jname{Xxxx. Xxx. Xxx. Xxx.}
\jvol{AA}
\jyear{2019}
\doi{10.1146/((no doi avaliable))}


% Document starts
\begin{document}

% Page header
\markboth{Ho}{Composite SED Clustering}

% Title
\title{Composite Spectral Energy Distributions and Bayesian Machine Learning for Spectral Data}

%Authors, affiliations address./
\author{Ming-Feng Ho$^1$
\affil{$^1$Department of Physics and Astronomy, University of California, Riverside; email: mho026@ucr.edu; website: \url{https://github.com/jibanCat} }}

%Abstract
\begin{abstract}
Extracting more information from photometric data can help astronomers to make intelligent decisions before taking the spectra.
Multi-wavelength photometry can achieve deeper and more extensive areas in the space and at the same time much cheaper than spectroscopic.
Composite \textsc{sed} method provides a new way to study high-redshift galaxies empirically.
By building composite \textsc{sed}s from grouping multi-wavelength photometric data, we can classify different galaxy types based on the spectral features shown in the composite \textsc{sed}s.
This new grouping method is potentially useful for classifying rare galaxy populations with photometric data solely.

We will also review two Bayesian machine learning method, Gaussian process and Dirichlet process, and the usage of Bayesian machine learning for modeling the spectral data.
\end{abstract}

%Keywords, etc.
\begin{keywords}
galaxies: evolution, galaxies: high-redshift, methods: data analysis, methods: Bayesian non-parametric
\end{keywords}
\maketitle

%Table of Contents
\tableofcontents


% Heading 1
\section{INTRODUCTION}
One fundamental dilemma in observational astronomy is that: do we want to take a spectrum or take a multi-wavelength photometric observation? 
Taking a spectrum will give us more detailed information about the properties of an object, e.g., emission lines and absorption lines. 
However, the exposure time of taking a spectrum is much longer than taking a multi-wavelength photometric observation. 

Using multi-wavelength photometry, on the other hand, is less expensive than taking a spectrum. 
The other advantage of multi-wavelength observations is that we can reach a deeper redshift and a wider spatial range.
However, the trade-off of multi-wavelength observations is that we lose the resolution of the spectral features of data.

The dilemma here is similar to the problem of \textbf{ exploration or exploitation } situation\footnote{A dilemma situation in the active (machine) learning problems.}:
whether you want to focus on taking accurate observations on a small number of objects or you want to explore a wider and deeper area but lose the accuracy?
Another analogy to the exploration or exploitation problem is the ``Battleship'' game\footnote{\url{https://en.wikipedia.org/wiki/Battleship_(game)}}.
In the Battleship game, we have to destroy our enemy's ships by guessing the locations of ships with a few trail shootings.
We have to make an intelligent choice to balance exploration and exploitation to win.
In typical cases, we would start by exploring the whole area; after gaining some low-resolution knowledge, we could start to focus on the plausible regions to find our enemy's hidden ships.

The game played by astronomers here is similar: should we choose to explore the space with a lower resolution by multi-wavelength photometry or exploit on a limited number of objects for taking expensive spectra?
To make an intelligent decision, we need to know more.
Since the budget is limited and the number of spectra we can take is also limited, gaining more information from multi-wavelength photometric data before taking spectra is essential.

Astronomers developed techniques including UVJ color-color diagram and \textsc{sed} fitting to gain more information from photometric data in order to make an optimal decision.
The color-color diagram classifies galaxies into quiescent or star-forming types; \textsc{sed} fitting estimates the properties of galaxies and redshifts (e.g., EAZY \citep{Brammer2008}) with the help of modeling of spectral energy distributions (\textsc{sed}s) and synthetic templates built by matrix factorization \citep{Blanton2007}.

\begin{marginnote}
    \entry{EAZY}: \textbf{E}azy and \textbf{A}ccurate \textbf{Z}photo from \textbf{Y}ale
    \entry{\textsc{sed}}: Spectral Energy Distribution
\end{marginnote}

One thing we can ask is: can we gain more knowledge about our targets beyond the UVJ diagram and \textsc{sed} fitting?
Composite \textsc{sed} technique \citep{Kriek2011, Forrest2018} provides an empirical way to cluster multi-wavelength targets together based on the shapes of \textsc{sed} fittings.
With the advance of medium-band photometry (See Fig\ref{fig:medium_bands}), we can achieve a finer sampling on the shapes of \textsc{sed}s and gain a better set of composite \textsc{sed}s.

By examining composite \textsc{sed}s, the rare populations, which are not easy to be identified in the UVJ diagram, could be classified based on the shapes of \textsc{sed}s.
If we gain more knowledge about our targets by using composite \textsc{sed}s, astronomers can make a better decision on which target is much more interesting to take a spectrum.
Usually, the marginal cases would be selected to be studied in more details\footnote{A similar technique in active learning is called ``uncertainty sampling''. In uncertainty sampling, we choose to study the most uncertain targets. By focusing on the boundary targets, we can learn faster (achieve a faster convergence). See \citet{Garnett18}.}.


% Heading 2
\section{GALAXY EVOLUTION IN TERMS OF COMPOSITE SPECTRAL ENERGY DISTRIBUTIONS (\textsc{sed}s)}

The development of composite \textsc{sed} method came from the improvement of medium-band photometry and the advance of \textsc{sed} fittings. 
In this section, we will first review the medium-band photometry technique.
Next, we will talk about the grouping method implemented in \citet{Kriek2011, Forrest2018}.
In the final part of this section, we will examine the classification of galaxy types via composite \textsc{sed}s using the spectral features such as $H_\alpha$ and $D(4000)$, and then we will talk about how these galaxy types are distributed on the UVJ diagram.

\begin{marginnote}
    \entry{$D(4000)$} : Balmer/4\,000 break
    \entry{$EW_{H_\alpha}$}: the equivalent width of the $H_\alpha$ emission line 
\end{marginnote}

% Heading 2.1
\subsection{Medium-Band Photometry at Near-IR}

The choice of photometric bands is crucial for accurate redshift estimations. 
And without accurate redshift estimations, astronomers will be unable to achieve accurate rest-frame colors.

Past deep optical surveys such as Classifying Object by Medium-Band Observations-17 (COMBO-17, \citet{Wolf2003}) and Cosmic Evolution Survey (COSMOS, \citet{Scoville2007}) achieved accurate photometric redshift accuracies with $ \sigma_{\Delta z / (1 + z_{spec})} \sim 1\% $ using medium-band photometry.
These surveys achieve a large sample size for $ z \sim 1 $; however, if we want to study high-redshift galaxies up to $ z \sim 3 $, we need to shift our filters to a higher wavelength region. 

The prominent spectral feature such as Balmer/4\,000 break is shifted to the near-IR region at $ z \sim 1.5 $.
To better sample the spectral features of high-redshift galaxies, the NEWFIRM Medium-Band Survey (NMBS, \citet{Whitaker2011}) and the FourStar galaxy evolution survey (ZFOURGE, \citet{Straatman2016}) placed multiple medium bands at near-IR regions (See Fig~\ref{fig:medium_bands}).
Fig~\ref{fig:z_photo} shows, with medium-band filters in near-IR, \texttt{FourStar} achieved a better constraint on the posterior of the photometric redshift. 


% fig: medium bands
\begin{figure}
    \includegraphics[width=6in, height=4in]{images/medium_bands.pdf}
    \caption{\texttt{Fourstar} medium bands (J1, J2, J3, Hs, Hl, Ks) in \citet{Straatman2016} (highlighted as red and yellow). The choice of medium bands would increase the resolution of sampling on the \textsc{sed}.}
    \label{fig:medium_bands}
\end{figure}

% fig: better z_photo
\begin{figure}
    \includegraphics[width=6in, height=2.5in]{images/z_photo_better.pdf}
    \caption{Sampling \textsc{sed} with or without \texttt{Fourstar} medium-band filters. With the help of \texttt{Fourstar} filters (red), the posterior distribution of photometric redshift (with \textsc{sed} fitting) is way more accurate.}
    \label{fig:z_photo}
\end{figure}

% Heading 2.2
\subsection{Composite Spectral Energy Distributions (\textsc{sed}s)}

Composite \textsc{sed} method gives us a new way to classify rare galaxy types using empirical \textsc{sed}s.
By grouping galaxies with similar \textsc{sed} shapes, we can increase the signal to noise and build the empirical \textsc{sed}s of different galaxy types.

The general grouping method is described in Fig~\ref{fig:grouping} and Algorithm~\ref{algorithm:grouping}. 
Three galaxy types identified in \citet{Kriek2011} are shown in Fig~\ref{fig:kreiksed} and six galaxy types identified in \citet{Forrest2018} are shown in Fig~\ref{fig:seds}. 
By using a larger dataset ($\sim$ 7\,000 galaxies) than NMBS ($\sim$ 3\,500 galaxies), ZFOURGE were able to pick up rare galaxy types such as \textbf{transitional galaxies} and \textbf{post-starbursts}.


% Heading 2.2.1
\subsubsection{Grouping Method}
 
The grouping approach which \citet{Kriek2011} and {Forrest2018} took to construct composite \textsc{sed}s is to compute the similarities (a root-mean-squared error metric) between different multi-wavelength photometric data at rest-frame.

Before we compute the similarity, we have to move the observed photometry back to rest-frame.
The $z$ we used to de-redshift (move to rest-frame) is estimated from \textsc{sed} template fitting, EAZY \citep{Brammer2008}.
After we de-redshift the observed photometry back to rest-frame, another problem arises: though we have our observed photometry data in the same wavelengths at observed wavelengths, they do not have the same rest-frame wavelengths.
How can we compare two galaxies with fluxes at different rest-frame wavelengths?

To resolve the problem, 22 artificial rest-frame filters were designed.
After we fit with the \textsc{sed} templates, we de-redshift the fitted \textsc{sed} back to rest-frame and bin the \textsc{sed} with 22 artificial filters.
Therefore, the photometric data from different redshifts are comparable now because they fall within the same 22 filters.

After binning with the rest-frame filters, we compute the similarity metric,

% similarity
\begin{equation}
    b_{12} = \sqrt{
            \frac{ 
                \sum{ (f^{rf1}_\lambda - a_{12} f^{rf2}_\lambda )^2 } 
            }{
                \sum{ (f^{rf1}_\lambda)^2 }
            }
    }
    \label{eq:similarity}
\end{equation}
with the scale factor $a_{12}$ between different galaxies,
\begin{equation}
    a_{12} = \frac{\sum{ f^{rf1}_\lambda f^{rf2}_\lambda }}{ \sum{ (f^{rf2}_\lambda )^2 } }.
    \label{eq:scale}
\end{equation}
Basically, the scale factor $a_{12}$ helps us to shift the observed fluxes to the same average flux, and the similarity metric $b_{12}$ gives us the deviations between two different \textsc{sed} shapes.

\begin{marginnote}
    \entry{$b_{12}$}: the similarity between the \textsc{sed} shapes of two galaxies
    \entry{$a_{12}$} : the scale factor between the average fluxes of two galaxies
\end{marginnote}

In \citet{Forrest2018}, they defined a threshold ($ b_{12} < 0.05 $) to group similar \textsc{sed} shapes. 
We first search the galaxies with largest number of analogues (galaxies with $b_{12} < 0.05$).
Next, we group them together and remove these galaxies from our samples.
We iterate this process until there is no galaxy has more than 19 analogues. 


% fig: grouping
\begin{figure}
    \includegraphics[width=5in, height=4in]{images/grouping.png}
    \caption{Grouping method for composite \textsc{sed} in \citet{Forrest2018}. First, we take the observed multi-wavelength photometry. Second, de-redshift the wavelengths to rest-frame. Next, scale the flux using $a_{12}$ (see Algorithm~\ref{algorithm:grouping}). In the final panel, we get the composite \textsc{sed} based on the similarity metric $b_{12} < 0.05$.}
    \label{fig:grouping}
\end{figure}
 
 
% EAZY: template
\begin{figure}
    \includegraphics[width=2.6in, height=2in]{images/EAZY.png}
    \caption{EAZY \citep{Brammer2008} templates were used in fitting the \textsc{sed} of galaxies in \citet{Forrest2018}.}
    \label{fig:EAZY}
\end{figure}


% grouping algorithm
\begin{algorithm}
    \KwData{Multi-wavelength photometry of galaxies within some redshift range}
    \KwResult{Composite \textsc{sed}s of different galaxy types}
    
    % init: grabbing data
    \tcp{Grab your data: fluxes and wavelengths}
    $ \mathbf{F}, \Lambda \leftarrow $ Multi-photometry of galaxies
    
    % rest-frame bins: determine using synthetic photometric filters
    \tcp{Bin: 22 rest-frame filters with equal widths between 1\,226 \AA $ < \lambda < $ 49\,580 \AA}
    $ Bin(\mathbf{\lambda}) = \mathrm{map}: \mathbf{\lambda} \rightarrow \mathbf{\lambda}[\log_{10}{1226}: \frac{1}{22} (\log_{10}{49580} - \log_{10}{1226}) i] $
    
    % fit with EAZY: determine redshift, de-redshift, and Bin with rest-from filters
    \tcp{Loop: modify each galaxy multi-wavelength flux}
    \For{$\mathbf{f}$ in $\mathbf{F}$, $\mathbf{\lambda}$ in $\mathbf{\Lambda} $}{
        % fitting
        \tcp{Fit: with EAZY to get continous flux function}
        $ f_\textsc{sed}, z_{photo} \leftarrow EAZY(\mathbf{d}) $

        % de-redshift
        \tcp{De-redshift: using photo-z}
        $ \lambda_{rest} \leftarrow \lambda / (1 + z_{photo}) $

        % rest-frame filters
        \tcp{Bin: update discrete flux vector with rest-frame filters}
        $\mathbf{F}[i, :] \leftarrow f_\textsc{sed}[Bin( \lambda_{rest} )]$
    }

    % similarity: using fractional squared-error to compute similarity
    % and append values to 
    \tcp{Similarity: use squared error to calculate similarity}
    $\mathbf{b} \leftarrow \mathrm{zeros}(N, N)$
    
    \For{$\mathbf{f}_i$ in $\mathbf{F}$}{
        \For{$\mathbf{f}_j$ in $\mathbf{F}$ if $j > i$}{
            \tcp{calculate scale factor; $\circ$: Hadamard (elementwise) product }
            $ a_{12} \leftarrow \mathrm{sum}(\mathbf{f}_i \circ \mathbf{f}_j) / \mathrm{sum}(\mathbf{f}_j^2) $

            \tcp{calculate similarity}
            $\mathbf{b}_{ij} \leftarrow ( \mathrm{sum}( (\mathbf{f}_i - a_{12}\mathbf{f}_j)^2 ) / \mathrm{sum}( \mathbf{f}_i^2 ) )^{1/2}$
        }
    }

    % get analogs
    \tcp{Get the analogues from samples with b < 0.05}
    $ \mathrm{ind} \leftarrow \mathrm{argsort}( \mathrm{sum}(\mathbf{b} < 0.05).axis(1) ) $

    $Composite_\textsc{sed} \leftarrow \mathrm{list}()$

    \For{i in ind}{
        
        \tcp{find analogues}
        $ i_{a} \leftarrow find( \mathrm{b}_i < 0.05 ) $

        \If{ $\mathrm{length}(i_{a} + i) < 19$ }{break}

        $ Composite_\textsc{sed}$.append( [$i_{a} + i$] )

        \tcp{remove analogues from our samples}

        $ ind$.remove( $[i_{a} + i]$ ) 
        
    }

    % short description
    \caption{Grouping galaxies together based on \textsc{sed} shape}
    \label{algorithm:grouping}
\end{algorithm}



% Heading 2.2.3
\subsubsection{Classification of Galaxy Types}

The classification of composite \textsc{sed}s is done by visually inspecting the following two spectral features,

% spectral features
\begin{itemize}
    \item $EW_{H_\alpha}$ : $H_\alpha$ equivalent width is an indicator for star-forming activities. Galaxies with a wider $EW_{H_\alpha}$ in their composite \textsc{sed} will have a higher chance to be star-forming galaxies. In \citet{Forrest2018}, $EW_{H_\alpha}$ is around 100 $\mathrm{\AA}$  for a typical star-forming galaxy. The correlation between star formation rate and the $EW_{H_\alpha}$ is shown in the right panel of the Fig~\ref{fig:correlation_kreik}.
    \item $D(4000)$ : the Balmer/4\,000 $\mathrm{\AA}$   break indicates the age of a galaxy. Older galaxies generally have higher $D(4000)$s. 
\end{itemize}

Combine with these two features, \citet{Forrest2018} classified five galaxy types (6 if we include dusty star-forming galaxies).
Fig~\ref{fig:correlation} and Fig~\ref{fig:correlation_kreik} show the correlation between Balmer/4\,000 break and $EW_{H_\alpha}$.
In Fig~\ref{fig:correlation}, from top left to bottom right corner are emission line galaxies (purple), star-forming galaxies (blue), transitional galaxies (green), post-starbursts (yellow), and quiescent galaxies (red).

Fig~\ref{fig:color-color} shows how different types of galaxies classified by composite \textsc{sed}s are distributed on the UVJ color-color diagram.
It is straightforward to see the composite \textsc{sed}s successfully classified the quiescent galaxies (red) and star-forming galaxies (blue).
Moreover, we additionally classified three more galaxy types on the color-color diagram: transitional galaxies (green), post-starbursts (yellow), and emission line galaxies (purple).
Also, these rare populations are not easy to be categorized by using the UVJ color-color diagram solely.

In \citet{Forrest2018}, they mentioned about the loss of diversity in the higher redshift regions. 
Their conclusion was that there might have less quiescent galaxies and more post-starbursts in the high-redshift regions.


% fig: Kriek galaxies types
\begin{figure}
    \includegraphics[width=5in, height=5in]{images/spectral_features.pdf}
    \caption{Three types of galaxies (red: quiescent; purple: dusty star-forming; blue: star-forming) identified in \citet{Kriek2011} using composite \textsc{sed}. Several spectroscopic features are labeled in the plot.}
    \label{fig:kreiksed}
\end{figure}

% fig: galaxy types
\begin{figure}
    \includegraphics[width=5in, height=6in]{images/galaxy_types.png}
    \caption{Six galaxy types identified by visual inspecting on two features: 4\,000 break $ D(4000) $ (an indicator of age) and H$_\alpha$ equivalent width (a probe of star formation activities).}
    \label{fig:seds}
\end{figure}

% fig: correlation SFR
\begin{figure}
    \includegraphics[width=6in, height=3in]{images/correlation_Ha_D4000.pdf}
    \caption{\textbf{Left panel}: correlation between $H_\alpha$ equivalent width and $D(4000)$; \textbf{Right panel}: correlation between $H_\alpha$ equivalent width and star formation rate.}
    \label{fig:correlation_kreik}
\end{figure}

% fig: correlation different types
\begin{figure}
    \includegraphics[width=6in, height=3in]{images/Forrest_Ha_D4000.pdf}
    \caption{The correlation between $H_\alpha$ equivalent width and $D(4000)$ in \citet{Forrest2018}. The special thing in this figure is that it labeled the types of galaxies: magenta for emission line galaxies, blue for star-forming galaxies, green for transitional galaxies (because they are in green valley), yellow for post starburst, and red for quiescent galaxies. }
    \label{fig:correlation}
\end{figure}


% fig: color-color diagram
\begin{figure}
    \includegraphics[width=5in, height=5in]{images/color-color.png}
    \caption{Color-color diagram in \citet{Forrest2018}. \textbf{Top}: Different colors represent different galaxy types classified by composite \textsc{sed}s. A special feature of classification using composite \textsc{sed} is that we can track the population of marginal (or rare) types of galaxies on the diagram, e.g., the transitional galaxies (green) and post-starbursts (yellow). \textbf{Bottom}: The distribution of number of analogue galaxies.}
    \label{fig:color-color}
\end{figure}

\begin{marginnote}
    \entry{ELG} : emission line galaxies 
    \entry{SFG} : star-forming galaxies
    \entry{(D)SFG} : dusty star-forming galaixies
    \entry{TG} : transitional galaxies 
    \entry{PSB} : post-starbursts
    \entry{QG} : quiescent galaxies
\end{marginnote}

% Summary Points
\begin{summary}[SUMMARY POINTS]
    \begin{enumerate}
        \item Composite \textsc{sed} is a technique to construct empirical \textsc{sed}s for a given group of galaxy type and increase the signal to noise for the spectral features.
        \item Spectral features such as $EW_{H_\alpha}$ and $D(4000)$ are used to distinguish different types of galaxies.
        \item Composite \textsc{sed}s are able to identify rare population of galaxies, such as transitional galaxies and post-starbursts. 
    \end{enumerate}
\end{summary}    


% Heading 3
\section{BAYESIAN MACHINE LEARNING}

Bayesian machine learning is a branch of machine learning which aims to solve machine learning problems from a Bayesian perspective. 
Instead of optimizing the parameters from data using an empirical loss function (e.g., a least-squared function), Bayesian methods build generative models to randomly sample data from parameters and try to maximize the likelihood between observed data and hidden parameters \citep{Barber2012}.

The difference between Bayesian statistics and Bayesian ``machine learning'' is that Bayesian ``machine learning'' is trying to approximate {\it non-linear} functions \citep{Bishop2003}. 
After the publish of \citet{Rasmussen2005}, learning unknown complicated functions from observed data using {\it Gaussian processes} (\textsc{gp}) became popular. 

% Heading 3.1
\subsection{Modeling Spectral Data using Gaussian Processes (\textsc{gp})}

A {\it Gaussian process} is a collection of random variables with any finite subset of these random variables to be a joint Gaussian distribution \citep{Rasmussen2005}. \textsc{gp} could be a powerful tool to model any functional data (continuous data) in a non-parametric way. 
By non-parametric, it means we use infinite many parameters to describe our function \citep{Gelman04}. \textsc{gp} could be treated as a random function (or a stochastic process) which draws samples from an n-dimensional distribution, 

% draw samples from a GP
\begin{equation}
    \mu(x_1), ..., \mu(x_n) \sim Normal((m(x_1), ..., m(x_n)), K(x_1, ..., x_n)).
    \label{eq:GP}
\end{equation}

% marginal note: GP
\begin{marginnote}[120pt]
    \entry{GP}: \textit{Gaussian Processes}
    \entry{$\sim$ Normal}: Sampling from a Gaussian (normal) distribution
    \entry{Bayesian ML}: Bayesian Machine Learning    
    \entry{K}: Covariance function (matrix)
    \entry{$\mu$}: Mean function
\end{marginnote} 

The construction of a \textsc{gp} could be considered as finding the mean function ($m(\vec x)$) and a suitable covariance function ($K(\vec x, \vec x')$). 
In normal cases, a zero mean is usually used as a prior for \textsc{gp} regressions. For $K(\vec x, \vec x')$, pre-defined covariance functions (e.g., a squared exponential function $\exp{(\frac{-r^2}{2 \ell^2})}$) are often been implemented. 
However, the usage of \textsc{gp} in modeling functional data will also be restricted by the intrinsic properties of the covariance functions.
Learning a suitable covariance function is the most crucial part of machine learning in \textsc{gp}.

Finding a suitable choice of covariance often reflects our interpretations of the characteristics of our data  \citep{Rasmussen2005}. 
For example, the usage of the squared potential function $\exp{(\frac{-r^2}{2 \ell^2})}$ implies the assumption that we believe each point on the function would have less impact to each other if they are far away on the functional space.
Therefore, we need a special kind of covariance function to suit our purpose of modeling spectral data.

\citet{Garnett17} took a machine learning approach to learn the covariance function, with a wavelength range from Ly$_\infty$ to Ly$\alpha$, from training data (quasar spectra). 
The optimization choice was to firstly decompose covariance matrix with \citep{Garnett2015},

% decomposition of the covariance
\begin{equation}
    \mathbf{K} = \mathbf{M}\mathbf{M}^{T},
    \label{eq:decompose}
\end{equation}
and then use the first 10 principle components of the flux of quasar spectra, $\mathbf{Y}$, to constitute the matrix $\mathbf{M}$. 
The optimization was done by maximizing the log-likelihood, $\mathcal{L}$, of the data by given $\mathbf{M}$ and absorption noise $\omega$, 

% log likelihood
\begin{equation}
    \mathcal{L}(\mathbf{M}, \omega) = \log{ p(\mathbf{Y} \mid \mathbf{\lambda}, \mathbf{\mu}, \mathbf{M}, \mathbf{N}, \omega, z_\mathrm{qso}, Model) }.
\end{equation}

The goal of optimizing above function is to find the optimal covariance matrix, $\mathbf{M}$, and absorption parameter, $\omega$, with some given conditions. Those conditions are a given mean vector $\mathbf{\mu}$, the noise on the spectra $\mathbf{N}$, the redshift of the \textsc{qso}, and with a given model. 
In a perspective of generative modeling, optimizing the data likelihood implies we are trying to find a covariance matrix to generate our spectral data better. 

% covariance for DLA
\begin{figure}
    \includegraphics[width=5in, height=5in]{images/covariance.pdf}
    \caption{Covariance function for quasar spectra in \citet{Garnett17}}
    \label{fig:covariance}
\end{figure}

The covariance matrix built by \citet{Garnett17} is shown in Fig~\ref{fig:covariance}. 
The scale in Fig~\ref{fig:covariance} represents the strength of correlations between pairs of rest-frame wavelengths on the \textsc{qso} spectra.
The features of the Lyman series are distinct.
The off-diagonal terms demonstrate the correlations of pairs of corresponding emission lines.

The mean function of \textsc{gp} modeling in \citet{Garnett17} can be simply obtained by stacking the training spectra, 

% stacking QSO spectra
\begin{equation}
    \mu_j = \mathrm{median } (y_{ij}),
\end{equation}
where $y_{ij}$ are the fluxes for spectrum. Fig~\ref{fig:mean_function} shows the mean function with a range from Ly$_\infty$ to Ly$\alpha$. 
The features of emission lines on the Lyman series is also quite obvious in the Fig~\ref{fig:mean_function}.

Generally, the \textsc{gp} model for spectral data could be described as
% full model for the spectral gaussian process
\begin{equation}
    p( \mathbf{y} \mid \mathbf{\lambda}, \mathbf{v}, \mathbf{\omega}, z, Model ) 
    = Normal( \mathbf{y}; \mathbf{\mu}, \mathbf{K} + \mathbf{\Omega} + \mathbf{V} ), 
\end{equation}
where $\mathbf{y}$ is the observed flux of the spectrum, 
$\mathbf{\lambda}$ is the spectroscopic grids we chose to bin the flux, 
$\mathbf{v}$ is the instrumental noise given by the observed data (they used \textsc{sdss} \textsc{qso} catalogue \citep{SDSS09} in \citet{Garnett17}), $z$ is the redshift dependence of the \textsc{gp} model, and $\omega$ is the absorption redshift dependence (it was used to model
 Ly$\alpha$ forest in \citet{Garnett17}). 
 
The beauty of generative modeling the spectrum using \textsc{gp} framework is that we can fully control the modeling of instrumental noise and redshift dependence uncertainties. 
Besides, the whole framework is transparent and flexible, which implies it is interpretable and future improvements are achievable. 


% mean function for DLA
\begin{figure}
    \includegraphics[width=5in, height=1.5in]{images/mean_function.pdf}
    \caption{Mean function for quasar spectra in \citet{Garnett17}}
    \label{fig:mean_function}
\end{figure}


% GP summary Points
\begin{summary}[SUMMARY POINTS]
    \begin{enumerate}
    \item \textit{Gaussian Processes}. A flexible Bayesian non-parametric framework which allows us to model any function.
    \item Learned covariance matrix $\mathbf{K}$. To model spectral data, we can optimize the covariance matrix using training data to acquire customized covariance function of any given range of wavelengths.
    \end{enumerate}
\end{summary}
    

% Heading 3.2
\subsection{Dirichlet Processes}

The \textit{Dirichlet process} \citep{Teh2006} is a Bayesian non-parametric method to model infinite mixture models and also could be used for clustering. 
We haven't seen any application of \textit{Dirichlet processes} (\textsc{dp}) in spctral data clustering. 
A recent astronomical application of \textsc{dp} is building a mixture model for binary neutron stars in the gravitational-wave data \citep{Pozzo2018}. 
Since we expect the application of \textsc{dp} in the clustering of spectral data is achievable in future; we decided to roughly review the basic concept of \textsc{dp} here.

The \textsc{dp} is a stochastic process which is often used to model mixture models. 
Each random sample in \textsc{dp} is itself a distribution, which means we can treat random samples of a \textsc{dp} as cluster centers of a mixture model. 
Similar to \textsc{gp}, a finite subset of a \textsc{dp} could be described by Dirichlet distributions.

To model the data $v$ using the Dirichlet mixture model,
the clustering memberships could be described by the following conditional probability \citep{Barber2012}, 

% indicator model
\begin{equation}
    p(v^{1:N} \mid \theta) = \sum_{z^{1:N}} p(v^{1:N} \mid z^{1:N}, \theta) p(z^{1:N}),
    \label{eq:indicator}
\end{equation}
where $p(z^{1:N})$ gives the priors over each cluster and $\theta$ describe the parameters of the cluster model. 
The choice of priors over clusters $p(z^{1:N}$ is crucial.


% Dirichlet PGM
\begin{figure}
    \includegraphics[width=6in, height=3in]{images/Dirichlet.pdf}
    \caption{The probabilistic graphical model of \textsc{dp} in plate notation in \citet{Barber2012}. The symbols here: $z$ is the indicator and $p(z^n)$ implies the prior over $n^{th}$ cluster; $v$ is data; $\theta$ is used to describe the parameters on the cluster model (the shared model) while $z$ could be treated as the hidden variable used to described component models (the individual models); $\pi$ here is the parameter of a Dirichlet distribution, which is used to describe distributions.}
    \label{fig:Dirichlet}
\end{figure}


% Heading 3.2.1
\subsubsection{Chinese Restaurant Process}

The clustering property of \textsc{dp} is hard to understand simply via mathematical forms above. 
However, there's an intuitive metaphor described in \citet{Teh2006} to mimic the process of drawing samples from a \textsc{dp} using a real-life example: \textit{Chinese Restaurant process} (\textsc{crp}).

The name of \textsc{crp} was developed in the 1980s. 
\textsc{crp} is a process to describe the distribution over partitions.

Now, imagine this: there is an infinite number of round tables in a Chinese restaurant, and there is also an infinite number of seats in each round table. 
Each customer will come to the restaurant one by one (just like sampling). 
Let us assume the first customer choose the first table.
Which table would next person choose?
If every customer is friendly\footnote{There are some literature discussed the unfriendly situations.}, the next customer may intend to choose the round table which has more people there.
Therefore, the probability of choosing $k^{th}$ table could be proportional to the number of people $n_k$ in that round table.
Nevertheless, she/he may also have a small amount of probability to choose a new empty table to sit depends on her/his mood of that day.

The mathematical form of \textsc{crp} can be described as 
\begin{equation}
    \theta_{n+1} \mid \theta_1 ..., \theta_{n} \sim \frac{1}{\alpha + n} \left( \alpha H + \sum_{k = 1}^{m} n_k \delta_{\theta_{k}^*} \right),
    \label{eq:crp}
\end{equation}
where $\alpha$ is a constant and $\delta_{\theta_k^*} = 1$ only when $\theta_k^*$ is selected.
The above equation is equivalent to \textsc{crp} in this way: 
\begin{enumerate}
    \item The first customer ($n = 0$): $\theta_1$ partition would be selected from a smooth distribution $H$.
    \item The second customer ($n = 1$): $\theta_2 \mid \theta_1$ partition would be selected from either $\frac{\alpha H}{\alpha + 1}$ (a new table) or $\frac{1}{\alpha + 1}$ (the table with customer 1).
    \item The $(n + 1)^{th}$ customer: $\theta_{n + 1} \mid \theta_n, ..., \theta_1$ would be selected from either $\frac{\alpha H}{n + \alpha}$ or $ \frac{\sum_{k = 1}^{m} n_k \delta_{\theta_k^*}}{\alpha + n} $.
\end{enumerate}


In the above \textsc{crp} scheme, the number of clusters will growth in logarithmic scale.
See Fig~\ref{fig:crp} for a cartoon version of \textsc{crp}.
Circles represent the round tables we have in the Chinese restaurant and the numbers represent the customers.
For the scheme of the 10-customer situation in Fig~\ref{fig:crp}, the joint probability is

\begin{equation}
    Pr(z_1, ..., z_{10}) = 
        \frac{\alpha}{\alpha}
        \frac{\alpha}{1 + \alpha}
        \frac{1}{2 + \alpha}
        \frac{\alpha}{3 + \alpha}
        \frac{1}{4 + \alpha}
        \frac{1}{5 + \alpha}
        \frac{2}{6 + \alpha}
        \frac{2}{7 + \alpha}
        \frac{2}{8 + \alpha}
        \frac{3}{9 + \alpha}.
    \label{eq:crp}
\end{equation}


% figure: chinese restaurant
\begin{figure}
    \includegraphics[width=3in, height=1in]{images/chinese_restaurant.pdf}
    \caption{An illustration of \textsc{crp} in \citet{Blei2007}.}
    \label{fig:crp}
\end{figure}


% Future Issues
\begin{issues}[FUTURE ISSUES]
\begin{enumerate}
    \item {\bf Classification of galaxy types }: the current way to label galaxy types in the composite \textsc{sed}s is to visually inspect the spectral features such as the equivalent width of $H_\alpha$ and the Balmer/4\,000 break. It is the curse of every unsupervised machine learning problems because you can not avoid using human eyes to label the data. 
    The easiest way is to use \citet{Forrest2018} as a training set, and train a supervised classifier on labeled data and use that classifier to predict the labels in the new dataset. 
    \item {\bf Building \textsc{dp} on top of \textsc{gp} }: one way to do clustering functional data is to build \textsc{dp} on top of \textsc{gp}. 
    We can first sample the partitions of cluster centers from \textsc{dp}, and use them as priors for the \textsc{gp}. 
    One issue is that if we want to learn the covariance function and the mean function from the data, we need to have a labeled training set with a finite number of classified types of galaxies. 
    ]In this way, \textsc{dp} would be unable to have an infinite number of cluster centers.
\end{enumerate}
\end{issues}

%Disclosure
% \section*{DISCLOSURE STATEMENT}
% If the authors have to note to disclose, the following statement will be used: The authors are not aware of any affiliations, memberships, funding, or financial holdings that
% might be perceived as affecting the objectivity of this review. 
 
% Acknowledgements
\section*{ACKNOWLEDGMENTS}

Thank the instructor Prof. Wilson for giving us this chance to practice writing a really long paper. 
It's fun because I took this chance to build my own \LaTeX environment on my new Linux laptop.
Thank Ben for the helpful discussions on the topic of composite \textsc{sed}.
Thank Prof. Bird and Prof. Garnett for helping me to learn Bayesian machine learning.

% References
\bibliographystyle{ar-style2}
\bibliography{sample}


\end{document}